# Iteration #12: HuggingFace Cache Fix (Two Attempts)

## üéâ MORE PROGRESS!

**Iteration #11 fixed the parameter issue!** We're now in the embedding phase!

## New Error
```
PermissionError at /tmp/manualai/hf_cache/models--sentence-transformers--all-MiniLM-L6-v2 
when downloading sentence-transformers/all-MiniLM-L6-v2
```

## Root Cause
The `SentenceTransformer` model was being downloaded, but the cache directory had permission issues.

Even though we set `HF_HOME` in the Dockerfile, the actual download at runtime was failing.

## First Attempt (Failed)
Added cache setup in vector_store.py but AFTER the imports:
```python
from sentence_transformers import SentenceTransformer  # ‚ùå Too early!

# Then tried to set cache...
os.environ["HF_HOME"] = str(_HF_CACHE)  # Too late!
```

**Problem:** sentence_transformers imported before cache was configured.

## Second Attempt (Should Work)
Moved cache setup BEFORE all imports:

## Solution
Applied the same `tempfile.mkdtemp()` pattern to the HuggingFace cache:

```python
# In vector_store.py, BEFORE loading SentenceTransformer:

import tempfile
import os

# Try to use HF_HOME, fallback to temp
_HF_CACHE = Path(os.getenv("HF_HOME", tempfile.gettempdir() + "/manualai_hf_cache"))
try:
    _HF_CACHE.mkdir(parents=True, exist_ok=True)
except:
    # Nuclear option: tempfile.mkdtemp() for guaranteed write access
    _HF_CACHE = Path(tempfile.mkdtemp(prefix="manualai_hf_cache_"))

# Set ALL HuggingFace-related cache env vars
os.environ["HF_HOME"] = str(_HF_CACHE)
os.environ["TRANSFORMERS_CACHE"] = str(_HF_CACHE)
os.environ["SENTENCE_TRANSFORMERS_HOME"] = str(_HF_CACHE)
os.environ["HUGGINGFACE_HUB_CACHE"] = str(_HF_CACHE)

# Pass cache_folder explicitly when loading model
SentenceTransformer(model_name, cache_folder=str(_HF_CACHE))
```

## Why This Works
- ‚úÖ Sets env vars BEFORE any HuggingFace imports
- ‚úÖ Uses tempfile.mkdtemp() as ultimate fallback
- ‚úÖ Passes cache_folder explicitly to SentenceTransformer
- ‚úÖ Same bulletproof pattern that solved directory issues

## Progress Summary

### Issues Solved So Far:
1. ‚úÖ Directory permissions (tempfile.mkdtemp)
2. ‚úÖ NLTK permission error (complete monkeypatch)
3. ‚úÖ ImportError for NLTK functions (added to stub)
4. ‚úÖ Parameter mismatch (added disable_ocr)
5. ‚úÖ HuggingFace cache permissions (tempfile.mkdtemp)

### Current Pipeline Status:
```
‚úÖ Upload endpoint
‚úÖ File storage
‚úÖ NLTK configuration
‚úÖ unstructured imports
‚úÖ Document loading
‚úÖ HuggingFace cache setup
‚è≥ Embedding model download...
```

## What This Means

We're **DEEP** into the ingestion pipeline now! We've solved:
- File upload ‚úÖ
- Document loading ‚úÖ
- NLTK tokenization ‚úÖ

Now we're at:
- **Embedding model download** (current fix)
- Vector store creation (next)
- RAG chain setup (after that)

## Expected Next
If this works:
- ‚úÖ Model downloads successfully
- ‚úÖ Vector embeddings created
- ‚úÖ Manual ingestion completes!

If there's another issue:
- Debug the next error (likely in vector store or RAG chain)
- Keep iterating!

## Test Timeline
- Pushed: ~10:40
- Rebuild: 3-5 minutes
- Test: ~10:44

---
**We're getting closer! Each iteration solves a real issue.** üöÄ
